{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_json(\"D:/Major Project/datasets/SC Dataset-20240615T035003Z-001/SC Dataset/newstext_1.json\")\n",
    "df_2 = pd.read_json(\"D:/Major Project/datasets/SC Dataset-20240615T035003Z-001/SC Dataset/newstext_2.json\")\n",
    "\n",
    "dataframe = [df_1,df_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Remove punctuation and non-Devanagari characters\n",
    "    text = re.sub(r'[^\\u0900-\\u097F\\s।]', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Normalize text\n",
    "    normalized_text = normalize_text(text)\n",
    "    with open('whole_corpus_processed.txt','w',encoding='utf-8') as f:\n",
    "        f.write(normalized_text)\n",
    "    sentences = normalized_text.split() # !?\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in append mode\n",
    "with open('_3_4_5_6_7_8_corpus.txt', 'a', encoding='utf-8') as file:\n",
    "    # Iterate over each DataFrame\n",
    "    for df in dataframe:\n",
    "        # Concatenate text data from the specified column\n",
    "        corpus = ''.join(df['newsText'])\n",
    "        # Append the corpus to the file\n",
    "        file.write(corpus + '\\n')  # add a newline character for separation between DataFrames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_1_8_corpus.txt', 'r',encoding='utf-8') as f:\n",
    "    load_corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45170546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(load_corpus))\n",
    "len(load_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = preprocess_text(load_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6818072"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['विकल्परहित', 'दोस्रो', 'चरण', 'शिवकुमार', 'भट्टराई', 'भनिन्छ', 'राजनीति', 'सम्भावनाको', 'खेल', 'हो', '।', 'तर', 'राजनीति', 'सम्भावनासँगै', 'कल्पनाबाहिरको', 'प्रपञ्चको', 'पुलिन्दासमेत', 'बन्न', 'पुगेको', 'छ', '।', 'नेपालको', 'पछिल्लो', 'राजनीतिक', 'परिघटनाले', 'यो', 'अवस्थाको', 'स्पष्ट', 'चित्रण', 'गरेको', 'छ', '।', 'सन्दर्भ', 'सत्ता', 'हस्तान्तरणको', 'हो', '।', 'गएको', 'साउन', '१९', 'गते', 'नेपाली', 'काँग्रेससँग', 'भद्रसहमति', 'गरी', 'स्थानीय', 'तहको', 'निर्वाचनको', 'कार्यभारसहित', 'पहिलो', 'चरणमा', 'पुष्पकमल', 'दाहाल', 'प्रचण्डको', 'नेतृत्वमा', 'संयुक्त', 'सरकार', 'बनाउने', 'भद्रसहमतिअनुसार', 'सरकार', 'बन्यो', '।', 'त्यसपछि', 'प्रदेश', 'र', 'केन्द्रको', 'निर्वाचन', 'गर्न', 'काँग्रेस', 'सभापति', 'शेरबहादुर', 'देउवा', 'नेतृत्वको', 'सरकार', 'निर्माण', 'गर्ने', 'भनिएको', 'हो', '।', 'पहिलो', 'चरणको', 'कार्यभार', 'लगभग', 'पूरा', 'गरेको', 'प्रचण्ड', 'सरकारले', 'पूर्वसहमतिबमोजिम', 'राजीनामा', 'गर्ने', 'तयारी', 'गरेपछि', 'प्रमुख', 'प्रतिपक्ष', 'एमालेमा', 'एकाएक', 'प्रचण्डप्रति', 'प्रचण्ड', 'सहानुभूतिको', 'भूत']\n"
     ]
    }
   ],
   "source": [
    "print(processed_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word = set(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273430"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set saved to unique_words.txt\n"
     ]
    }
   ],
   "source": [
    "def save_set_to_txt_file(word_set, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        for word in word_set:\n",
    "            file.write(word + \"\\n\")\n",
    "\n",
    "output_file = \"unique_words.txt\"\n",
    "\n",
    "save_set_to_txt_file(unique_word, output_file)\n",
    "print(f\"Set saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save set to a pickle file\n",
    "with open(\"unique_words.pickle\", \"wb\") as file:\n",
    "    unique_word_list = list(unique_word)\n",
    "    pickle.dump(unique_word_list, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set from pickle file\n",
    "with open(\"unique_words.pickle\", \"rb\") as file:\n",
    "    loaded_set = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'प्युठानको'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_set[273429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spell_checker_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
